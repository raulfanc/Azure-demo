{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spark job to run on Data Lake notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ShortType, DateType\n",
    "from pyspark.sql.functions import col, datediff\n",
    "\n",
    "# define schema\n",
    "schema = StructType([\n",
    "    StructField(\"Rego\", StringType(), True),\n",
    "    StructField(\"Brand\", StringType(), True),\n",
    "    StructField(\"Model\", StringType(), True),\n",
    "    StructField(\"Trim\", StringType(), True),\n",
    "    StructField(\"Year\", ShortType(), True),\n",
    "    StructField(\"Odometer\", IntegerType(), True),\n",
    "    StructField(\"Price\", IntegerType(), True),\n",
    "    StructField(\"Date listed\", DateType(), True),\n",
    "    StructField(\"Date removed\", DateType(), True),\n",
    "    StructField(\"Turnover\", ShortType(), True)\n",
    "])\n",
    "\n",
    "# Read the JSON files into a Spark DataFrame\n",
    "df = spark.read.json(\"/mnt/bronze\", schema=schema)\n",
    "\n",
    "# Apply transformations\n",
    "df = df.withColumn(\"Turnover\", datediff(col(\"Date removed\"), col(\"Date listed\")).cast(\"int\"))\n",
    "# Apply transformations\n",
    "df = df.withColumn(\"Turnover\", datediff(col(\"Date removed\"), col(\"Date listed\")).cast(\"int\"))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the data from the Delta table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delta_df = spark.read.format(\"delta\").load(\"/mnt/delta/usedCarSales\")\n",
    "delta_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `spark.conf` to optimize performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ShortType, DateType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, datediff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finetune Spark settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: all tables will be broadcast. -1 is broadcast join is disabled\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1) \n",
    "\n",
    "# parallelism running, the more partitions, the more computing intensive\n",
    "# ONLY for data shuffling, joining, and aggregating can run 5\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5)\n",
    "\n",
    "# Numbers of parallelism running for ALL TASKS\n",
    "# apart from shuffling, joining, and aggregating, all other jobs can run 10 \n",
    "spark.conf.set(\"spark.default.parallelism\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"UsedCarSalesData\").getOrCreate()\n",
    "\n",
    "# define schema (desired `dtypes` and the `order of columns`)\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Rego\", StringType(), True),\n",
    "    StructField(\"Brand\", StringType(), True),\n",
    "    StructField(\"Model\", StringType(), True),\n",
    "    StructField(\"Trim\", StringType(), True),\n",
    "    StructField(\"Year\", ShortType(), True),\n",
    "    StructField(\"Odometer\", IntegerType(), True),\n",
    "    StructField(\"Price\", IntegerType(), True),\n",
    "    StructField(\"Date listed\", DateType(), True),\n",
    "    StructField(\"Date removed\", DateType(), True),\n",
    "    StructField(\"Turnover\", ShortType(), True)\n",
    "])\n",
    "\n",
    "# Spark Join\n",
    "df = spark.read.json(\"raw data/new_listing_*.json\", schema=schema)\n",
    "# Spark Transformation\n",
    "df = df.withColumn(\"Turnover\", datediff(col(\"Date removed\"), col(\"Date listed\")).cast(\"int\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d187f2e9dee7598edc4a688ec32edfe3d7a2f237f4345d12f00c29e3ea6101bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
